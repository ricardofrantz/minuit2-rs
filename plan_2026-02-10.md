# Full Revision Plan: minuit2-rs

Date: 2026-02-10

Note:
- This plan started from a standalone extraction baseline.
- Active canonical upstream for the port is now defined as ROOT Minuit2:
  - `https://github.com/root-project/root/tree/master/math/minuit2`
  - target release baseline: `v6-36-08`

## Goal

Do a full technical revision of the Rust port against original Minuit2, with:
- complete function-level parity accounting (every upstream function accounted for),
- full coverage metrics (core + all-features),
- benchmark baselines and regression tracking.

## Baseline (measured now)

- Test status:
  - `cargo test --no-default-features`: pass
  - `cargo test --all-features`: fails on this machine unless `PYO3_USE_ABI3_FORWARD_COMPATIBILITY=1` is set (Python 3.14 vs PyO3 0.23 max 3.13)
  - `PYO3_USE_ABI3_FORWARD_COMPATIBILITY=1 cargo test --all-features`: pass
- Coverage status:
  - `cargo llvm-cov --no-default-features --summary-only`: 77.64% lines, 74.07% functions
  - `PYO3_USE_ABI3_FORWARD_COMPATIBILITY=1 cargo llvm-cov --all-features --summary-only`: 72.68% lines, 67.65% functions
  - 0% modules currently include `src/minimize/mod.rs`, `src/application.rs`, and `src/python.rs`
- Bench status:
  - Existing Criterion suite runs 5 scenarios (Migrad/Simplex/Hesse pipeline only)
  - Measured medians (current machine):
    - Rosenbrock 2D Migrad: ~15.37 us
    - Rosenbrock 2D Simplex: ~6.65 us
    - Quadratic 4D Migrad: ~4.22 us
    - Quadratic 2D Migrad+Hesse: ~5.26 us
    - Gaussian fit Migrad+Hesse: ~10.69 us

## Execution Status (2026-02-10 update)

Completed:
- Phase 1 parity artifact generation is in place and reproducible:
  - `scripts/generate_parity_report.py --commit 57dc936a2b74d0b4dda1254c3dd63e7c61a97c84`
  - Current counts: implemented=183, missing=64, needs-review=169, intentionally-skipped=41 (457 rows)
- Coverage closure work partially completed:
  - Added tests for `MnMinimize`, application defaults, scan serial/parallel equivalence, and expanded Minos/Contours method coverage.
  - Added explicit serial and parallel scan paths (`scan_serial` / `scan_parallel`) and aligned docs to real API.
  - New measured totals:
    - Core (`--no-default-features`): 82.34% lines, 81.10% functions
    - All-features (`--all-features`): 77.55% lines, 75.23% functions
  - Reports generated:
    - `reports/coverage/core_coverage.md`
    - `reports/coverage/all_features_coverage.md`
- Benchmark expansion completed for Phase 4 scope:
  - Added benchmarks for `MnMinimize`, `MnMinos`, `MnContours`, `MnScan` serial/parallel, and kernel benches (`make_pos_def`, `mn_linesearch`).
  - Baseline report generated:
    - `reports/benchmarks/benchmark_baseline.md`
  - Notable result: for 101-point scan workload, `scan_parallel` is slower than serial on this machine (~27.51 us vs ~2.05 us).

Still open:
- Full parity closure to 100% “implemented/replaced/intentionally-skipped” is not complete (`missing` + `needs-review` remain).
- Python module coverage remains 0% in all-features run (`src/python.rs`), requiring dedicated binding tests.

## Known Gaps Found During Investigation

1. Feature requirement mismatch:
- `README.md` and `DOC.md` claim parallel `MnScan` via `rayon`, but `src/scan/mod.rs` currently has no `rayon` usage.

2. Python feature fragility:
- `Cargo.toml` uses `pyo3 = "0.23"`; local all-features builds fail under Python 3.14 unless ABI3 forward-compat env var is set.

3. Coverage holes:
- `MnMinimize` has no test coverage.
- Python bindings have no tests.
- Minos internals and user state/error modules are relatively low coverage.

4. Parity uncertainty vs upstream:
- `INVENTORY.md` is file-level, not function-level; no authoritative function-by-function parity artifact exists yet.
- A quick name-level cross-check found 20 `Port` symbols from `INVENTORY.md` with no direct symbol-name evidence in `src/` yet (needs explicit classification in parity matrix).

## Execution Plan

### Phase 1: Build Authoritative Function Parity Matrix

1. Pin upstream baseline commit for comparison (GooFit/Minuit2).
2. Extract upstream function/method symbols from all `Port` entries in `INVENTORY.md` (AST-based extraction preferred).
3. Extract Rust symbols from `src/` (public + internal where relevant to mapped upstream functions).
4. Produce `reports/parity/functions.csv` with columns:
   - upstream file
   - upstream symbol
   - Rust file
   - Rust symbol
   - status: `implemented` | `replaced` | `intentionally-skipped` | `missing` | `needs-review`
   - evidence (file:line)
5. Produce `reports/parity/gaps.md` with grouped missing/ambiguous items and priority.

Acceptance gate:
- 100% of upstream symbols in scope are accounted for in one status bucket.

### Phase 2: Behavior Equivalence Audit (Rust vs Upstream)

1. Define canonical workload suite (deterministic):
   - quadratic (2D/ND),
   - Rosenbrock,
   - bounded problems,
   - Gaussian fit,
   - difficult landscape (Goldstein-Price),
   - Minos/Contours/Scan scenarios.
2. Run both implementations and compare:
   - convergence validity,
   - parameter estimates,
   - fval/edm/nfcn,
   - covariance and Minos asymmetry where applicable.
3. Add differential tests in Rust for deviations beyond tolerance.

Acceptance gate:
- All workloads pass tolerance thresholds (to be documented per metric).

### Phase 3: Coverage Closure

1. Add targeted tests for uncovered/low modules:
   - `src/minimize/mod.rs`,
   - `src/application.rs`,
   - `src/minos/*`,
   - `src/minimum/error.rs`,
   - `src/user_parameter_state.rs`,
   - `src/python.rs` (feature-gated tests).
2. Add feature-matrix tests:
   - default,
   - `--no-default-features`,
   - `--features parallel`,
   - `--features python`.
3. Capture coverage artifacts for both:
   - core (`--no-default-features`)
   - all-features.

Acceptance gate:
- Core coverage target: >= 90% line, >= 85% function.
- All-features target: >= 85% line, >= 80% function.

### Phase 4: Benchmark Expansion and Regression Framework

1. Expand `benches/benchmarks.rs` to include:
   - `MnMinimize`,
   - `MnMinos`,
   - `MnContours`,
   - `MnScan` (serial and parallel mode),
   - selected kernel-level benches (line search, gradient calculators, posdef correction).
2. Record benchmark metadata and stable baseline snapshots.
3. Add regression policy (threshold-based fail/warn per benchmark family).
4. Add optional upstream C++ comparison benchmarks for matched workloads.

Acceptance gate:
- Complete benchmark report with baseline table and pass/fail regression criteria.

### Phase 5: CI and Requirement Hardening

1. Resolve Python compatibility path:
   - prefer upgrading PyO3 if available, else explicit CI pin/env strategy.
2. Align docs with reality:
   - implement actual parallel scan or remove/qualify claims.
3. Enforce coverage and benchmark checks in CI with artifacts uploaded.
4. Keep parity report as a versioned CI artifact.

Acceptance gate:
- CI green across test/lint/security/miri/coverage/bench with explicit feature policy.

## Deliverables

- `reports/parity/functions.csv`
- `reports/parity/gaps.md`
- `reports/coverage/core_coverage.md`
- `reports/coverage/all_features_coverage.md`
- `reports/benchmarks/benchmark_baseline.md`
- updated tests/benches/CI/docs matching measured behavior

## Proposed Work Order (commits)

1. Parity matrix tooling + first report.
2. Differential tests and functional fixes.
3. Coverage-focused tests and feature matrix fixes.
4. Benchmark expansion and regression harness.
5. CI + docs hardening and final summary report.
